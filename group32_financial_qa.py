import pandas as pd
import re
import json
from pathlib import Path
import numpy as np
import uuid
import time
from typing import List, Dict, Any

from sentence_transformers import SentenceTransformer, CrossEncoder
import faiss
import tiktoken
from sklearn.feature_extraction.text import TfidfVectorizer
from rank_bm25 import BM25Okapi
import streamlit as st

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, Trainer, TrainingArguments
import torch

from PyPDF2 import PdfReader

# Global variables for storing data
chunks = []
metadata = []
embeddings = None
vector_index = None
bm25_index = None
tfidf_vectorizer = None
reranker = None
embedding_model = None


# 1. Data Collection & Preprocessing
class FinancialProcessor:
    def __init__(self):
        self.qa_pairs = []
        self.sections = {}

    def extract_text(self, file_path):
        """Extract text from PDF, Excel, HTML, or TXT files"""
        p = Path(file_path)

        if p.suffix.lower() == '.pdf':
            try:
                reader = PdfReader(str(p))
                text = ""
                for page in reader.pages:
                    text += page.extract_text() or ""
                return text
            except Exception as e:
                print(f"Error reading PDF {p}: {e}")
                return ""

        elif p.suffix.lower() in ['.xlsx', '.xls']:
            text = ""
            try:
                xl = pd.ExcelFile(p)
                for sheet in xl.sheet_names:
                    df = pd.read_excel(p, sheet_name=sheet)
                    text += f"\n=== {sheet} ===\n{df.to_string()}\n"
            except Exception as e:
                print(f"Error reading Excel {p}: {e}")
            return text

        else:  # .txt
            try:
                with open(p, 'r', encoding='utf-8') as f:
                    return f.read()
            except Exception as e:
                print(f"Error reading text file {p}: {e}")
                return ""

    def clean_text(self, text):
        """Clean and normalize text"""
        if not text:
            return ""
        # Remove noise
        text = re.sub(r'Page \d+.*?|Confidential.*?|Â©.*?reserved', '', text, flags=re.I)
        text = re.sub(r'http\S+|\S+@\S+', '', text)  # URLs and emails
        text = re.sub(r'\s+', ' ', text).strip()
        return text

    def segment_document(self, text, doc_name):
        """Segment document into financial sections"""
        if not text:
            return {'general': ''}
            
        sections = {'general': text}

        patterns = {
            'income': r'income statement|profit.*loss|consolidated.*income',
            'balance': r'balance sheet|financial position',
            'cashflow': r'cash flow|statement.*cash',
            'equity': r'equity|shareholders.*equity'
        }

        for section, pattern in patterns.items():
            matches = list(re.finditer(pattern, text, re.I))
            if matches:
                start = max(0, matches[0].start() - 200)
                end = min(len(text), matches[0].end() + 2000)
                sections[section] = text[start:end]

        self.sections[doc_name] = sections
        return sections

    def extract_financials(self, text):
        """Extract financial figures from text - FIXED VERSION"""
        if not text:
            return {}
            
        results = {}
        
        # More comprehensive patterns for financial data extraction
        patterns = {
            'revenue': [
                r'(?:total\s+)?revenue[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'(?:total\s+)?sales[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ],
            'income': [
                r'net\s+income[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'(?:net\s+)?profit[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'(?:net\s+)?earnings[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ],
            'assets': [
                r'total\s+assets[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'(?:total\s+)?assets[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ],
            'debt': [
                r'(?:total\s+)?debt[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'borrowings[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ],
            'equity': [
                r'(?:shareholders?\s+)?equity[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'stockholders?\s+equity[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ],
            'cash': [
                r'cash(?:\s+and\s+equivalents)?[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?',
                r'cash\s+holdings?[:\s]*\$?\s*(\d+(?:\.\d+)?)\s*(billion|million|thousand)?'
            ]
        }

        for metric, pattern_list in patterns.items():
            for pattern in pattern_list:
                match = re.search(pattern, text, re.I)
                if match:
                    amount = match.group(1)
                    unit = match.group(2) if match.group(2) else ''
                    results[metric] = f"${amount}" + (f" {unit}" if unit else "")
                    break  # Take first match for each metric

        return results

def chunk_text(text: str, chunk_size: int = 400, overlap: int = 50) -> List[str]:
    """Split text into chunks with overlap"""
    if not text or not isinstance(text, str):
        return []
        
    try:
        tokenizer = tiktoken.get_encoding("cl100k_base")
        tokens = tokenizer.encode(text)
        chunks = []

        for i in range(0, len(tokens), chunk_size - overlap):
            chunk_tokens = tokens[i:i + chunk_size]
            chunk_text = tokenizer.decode(chunk_tokens)
            chunks.append(chunk_text)

        return chunks
    except:
        # Fallback to word-based chunking
        words = text.split()
        chunks = []
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            if chunk.strip():  # Only add non-empty chunks
                chunks.append(chunk)
        return chunks

def process_documents(documents: Dict[str, Dict], chunk_sizes: List[int] = [100, 400]):
    """Process documents into chunks with metadata"""
    global chunks, metadata
    chunks, metadata = [], []

    if not documents:
        print("No documents provided")
        return chunks, metadata

    for doc_name, sections in documents.items():
        if not sections:
            continue
            
        for section_name, text in sections.items():
            if not isinstance(text, str) or len(text.strip()) < 10:
                continue

            for chunk_size in chunk_sizes:
                doc_chunks = chunk_text(text, chunk_size)

                for i, chunk in enumerate(doc_chunks):
                    if chunk.strip():  # Only add non-empty chunks
                        chunks.append(chunk)
                        metadata.append({
                            'chunk_id': str(uuid.uuid4()),
                            'document': doc_name,
                            'section': section_name,
                            'chunk_size': chunk_size,
                            'index': i,
                            'char_count': len(chunk)
                        })

    print(f"Created {len(chunks)} chunks from {len(documents)} documents")
    return chunks, metadata

# ====================== EMBEDDING & INDEXING ======================

def build_dense_index(chunks_input: List[str], model_name: str = "all-MiniLM-L6-v2"):
    """Build FAISS dense vector index"""
    global embeddings, vector_index, embedding_model

    if not chunks_input:
        print("No chunks provided for indexing")
        return None

    try:
        print("Building dense vector index...")
        embedding_model = SentenceTransformer(model_name)
        embeddings = embedding_model.encode(chunks_input, show_progress_bar=True)

        # Normalize for cosine similarity
        faiss.normalize_L2(embeddings)

        # Build FAISS index
        dimension = embeddings.shape[1]
        vector_index = faiss.IndexFlatIP(dimension)
        vector_index.add(embeddings.astype('float32'))

        print(f"Dense index built with {vector_index.ntotal} vectors")
        return embedding_model
    except Exception as e:
        print(f"Error building dense index: {e}")
        return None

def build_sparse_index(chunks_input: List[str]):
    """Build BM25 and TF-IDF sparse indexes"""
    global bm25_index, tfidf_vectorizer

    if not chunks_input:
        print("No chunks provided for sparse indexing")
        return

    try:
        print("Building sparse indexes...")

        # Preprocess text for BM25
        tokenized_chunks = [chunk.lower().split() for chunk in chunks_input]
        bm25_index = BM25Okapi(tokenized_chunks)

        # Build TF-IDF index
        tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
        tfidf_vectorizer.fit(chunks_input)

        print("Sparse indexes built")
    except Exception as e:
        print(f"Error building sparse indexes: {e}")

def load_reranker(model_name: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"):
    """Load cross-encoder for reranking"""
    global reranker
    try:
        print("Loading reranker...")
        reranker = CrossEncoder(model_name)
        return reranker
    except Exception as e:
        print(f"Error loading reranker: {e}")
        return None

# ====================== RETRIEVAL PIPELINE ======================

def preprocess_query(query: str) -> str:
    """Clean and preprocess query"""
    if not query:
        return ""
    query = query.lower().strip()
    query = re.sub(r'[^\w\s]', '', query)
    return query

def dense_retrieval(query: str, embedding_model_param, top_k: int = 10) -> List[Dict]:
    """Dense retrieval using vector similarity"""
    global vector_index, chunks, metadata
    
    # Check if all required components are available
    if vector_index is None:
        print("Vector index not available")
        return []
        
    if embedding_model_param is None:
        print("Embedding model not available")
        return []
        
    if not chunks:
        print("No chunks available")
        return []
    
    try:
        query_embedding = embedding_model_param.encode([query])
        faiss.normalize_L2(query_embedding)

        scores, indices = vector_index.search(query_embedding.astype('float32'), min(top_k, len(chunks)))

        results = []
        for score, idx in zip(scores[0], indices[0]):
            if idx >= 0 and idx < len(chunks):
                results.append({
                    'chunk_idx': int(idx),
                    'score': float(score),
                    'text': chunks[idx],
                    'metadata': metadata[idx] if idx < len(metadata) else {}
                })

        return results
    except Exception as e:
        print(f"Error in dense retrieval: {e}")
        return []

def sparse_retrieval(query: str, top_k: int = 10) -> List[Dict]:
    """Sparse retrieval using BM25"""
    global bm25_index, chunks, metadata
    
    if bm25_index is None or not chunks:
        print("BM25 index or chunks not available")
        return []
    
    try:
        query_tokens = preprocess_query(query).split()
        if not query_tokens:
            return []
            
        scores = bm25_index.get_scores(query_tokens)

        # Get top-k indices
        top_indices = np.argsort(scores)[-min(top_k, len(scores)):][::-1]

        results = []
        for idx in top_indices:
            if scores[idx] > 0 and idx < len(chunks):
                results.append({
                    'chunk_idx': int(idx),
                    'score': float(scores[idx]),
                    'text': chunks[idx],
                    'metadata': metadata[idx] if idx < len(metadata) else {}
                })

        return results
    except Exception as e:
        print(f"Error in sparse retrieval: {e}")
        return []

def hybrid_retrieval(query: str, embedding_model_param, top_k: int = 5) -> List[Dict]:
    """Combine dense and sparse retrieval"""
    if not query:
        return []
        
    dense_results = dense_retrieval(query, embedding_model_param, top_k)
    sparse_results = sparse_retrieval(query, top_k)

    # If both methods fail, return empty list
    if not dense_results and not sparse_results:
        return []

    # Combine results (union)
    combined = {}

    # Add dense results with weight
    for result in dense_results:
        idx = result['chunk_idx']
        combined[idx] = {
            **result,
            'combined_score': result['score'] * 0.7  # Weight dense higher
        }

    # Add sparse results
    for result in sparse_results:
        idx = result['chunk_idx']
        if idx in combined:
            combined[idx]['combined_score'] += result['score'] * 0.3
        else:
            combined[idx] = {
                **result,
                'combined_score': result['score'] * 0.3
            }

    # Sort by combined score
    final_results = sorted(combined.values(), key=lambda x: x['combined_score'], reverse=True)
    return final_results[:top_k]

def rerank_results(query: str, results: List[Dict], top_k: int = 3) -> List[Dict]:
    """Rerank results using cross-encoder"""
    global reranker
    
    if not reranker or not results:
        return results[:top_k]

    try:
        # Prepare pairs for reranking
        pairs = [(query, result['text']) for result in results]
        scores = reranker.predict(pairs)

        # Update scores and sort
        for i, result in enumerate(results):
            result['rerank_score'] = float(scores[i])

        reranked = sorted(results, key=lambda x: x['rerank_score'], reverse=True)
        return reranked[:top_k]
    except Exception as e:
        print(f"Error in reranking: {e}")
        return results[:top_k]

# ====================== RESPONSE GENERATION ======================

def load_generator(model_name: str = "distilgpt2"):
    """Load generative model"""
    try:
        print(f"Loading generator: {model_name}")
        generator = pipeline("text-generation", model=model_name,
                        tokenizer=model_name, pad_token_id=50256)
        return generator
    except Exception as e:
        print(f"Error loading generator: {e}")
        return None

def generate_answer(query: str, retrieved_chunks: List[Dict], generator) -> str:
    """Generate answer using retrieved context"""
    if not retrieved_chunks:
        return "I couldn't find relevant information to answer your question."

    if not generator:
        return "Generator model not available."

    # Prepare context
    context = "\n".join([chunk['text'][:200] for chunk in retrieved_chunks[:3]])
    prompt = f"Context: {context}\n\nQuestion: {query}\n\nAnswer:"

    try:
        response = generator(prompt, max_new_tokens=50,
                           do_sample=True, temperature=0.7, num_return_sequences=1)

        full_text = response[0]['generated_text']
        answer = full_text[len(prompt):].strip()
        return answer if answer else "Unable to generate a complete answer."

    except Exception as e:
        print(f"Error generating answer: {e}")
        return f"Error generating answer: {str(e)}"

# ====================== GUARDRAILS ======================

def input_guardrail(query: str) -> Dict[str, Any]:
    """Validate input query"""
    issues = []

    if not query:
        issues.append("Query is empty")
        return {'valid': False, 'issues': issues, 'processed_query': ''}

    # Check length
    if len(query.strip()) < 5:
        issues.append("Query too short")

    if len(query) > 500:
        issues.append("Query too long")

    # Check for financial relevance
    financial_keywords = ['revenue', 'profit', 'income', 'assets', 'debt', 'equity', 'cash', 'sales']
    if not any(keyword in query.lower() for keyword in financial_keywords):
        issues.append("Query may not be financial-related")

    return {
        'valid': len(issues) == 0,
        'issues': issues,
        'processed_query': preprocess_query(query)
    }

def output_guardrail(answer: str, query: str, retrieved_chunks: List[Dict]) -> Dict[str, Any]:
    """Validate output answer"""
    issues = []
    confidence = 0.5

    # Handle None or non-string answers
    if not answer or not isinstance(answer, str):
        return {'confidence': 0.1, 'issues': ['Invalid answer'], 'safe': False}

    # Check if answer contains numbers (good for financial queries)
    if re.search(r'\$?\d+', answer):
        confidence += 0.3

    # Check if answer relates to retrieved context
    if retrieved_chunks and any(chunk.get('combined_score', 0) > 0.7 for chunk in retrieved_chunks):
        confidence += 0.2

    # Check for hallucination indicators
    hallucination_phrases = ['i think', 'probably', 'might be', 'i believe']
    if any(phrase in answer.lower() for phrase in hallucination_phrases):
        issues.append("Potential hallucination detected")
        confidence -= 0.2

    return {
        'confidence': max(0, min(1, confidence)),
        'issues': issues,
        'safe': len(issues) == 0
    }

def read_pdfs_from_directory(directory: str) -> dict:
    """Read PDF files from a given directory and segment them into sections."""
    documents = {}
    processor = FinancialProcessor()
    pdf_dir = Path(directory)
    
    if not pdf_dir.exists():
        print(f"Directory {directory} does not exist, creating sample data")
        return create_sample_documents()
    
    for pdf_file in pdf_dir.glob("*.pdf"):
        try:
            text = processor.extract_text(str(pdf_file))
            if text:
                text = processor.clean_text(text)
                sections = processor.segment_document(text, pdf_file.stem)
                documents[pdf_file.stem] = sections
        except Exception as e:
            print(f"Failed to process {pdf_file.name}: {e}")
    
    if not documents:
        print("No PDF files found, creating sample data")
        return create_sample_documents()
        
    return documents

def create_sample_documents():
    """Create sample financial documents"""
    return {
        'tcs_2024': {
            'income': """TCS Corp 2024 Income Statement:
                        Total revenue: $4.13 billion
                        Net income: $530 million
                        Operating expenses: $1.5 billion
                        Gross profit: $2.63 billion""",
            'balance': """TCS Corp 2024 Balance Sheet:
                         Total assets: $7.0 billion
                         Total debt: $2.0 billion
                         Shareholders equity: $3.5 billion
                         Cash and equivalents: $800 million""",
            'general': """TCS Corp is a leading technology services company. 
                         This annual report covers fiscal year 2024 performance."""
        },
        'tcs_2025': {
            'income': """TCS Corp 2025 Income Statement:
                        Total revenue: $4.9 billion
                        Net income: $800 million
                        Operating expenses: $1.7 billion
                        Gross profit: $3.2 billion""",
            'balance': """TCS Corp 2025 Balance Sheet:
                         Total assets: $8.0 billion
                         Total debt: $2.2 billion
                         Shareholders equity: $4.0 billion
                         Cash and equivalents: $1.1 billion""",
            'general': """TCS Corp continued growth in 2025 with strong performance 
                         across all business segments."""
        }
    }

class FineTunedFinancialQA:
    """Fine-tuned model for financial Q&A - FIXED VERSION"""
    
    def __init__(self):
        self.model = None
        self.tokenizer = None
        self.qa_pipeline = None
        self.training_data = None
        self.model_trained = False
        self.knowledge_base = {}
        
    def generate_training_data(self, documents: Dict[str, Dict]) -> List[Dict]:
        """Generate training Q&A pairs from financial documents - FIXED"""
        training_data = []
        
        # Define question templates and patterns for financial data
        question_templates = {
            'revenue': [
                "What was {company}'s revenue in {year}?",
                "How much revenue did {company} generate in {year}?",
                "What were {company}'s sales in {year}?"
            ],
            'income': [
                "What was {company}'s net income in {year}?",
                "How much profit did {company} make in {year}?",
                "What were {company}'s earnings in {year}?"
            ],
            'assets': [
                "What were {company}'s total assets in {year}?",
                "How much in assets did {company} have in {year}?",
                "What was {company}'s asset value in {year}?"
            ],
            'debt': [
                "How much debt did {company} have in {year}?",
                "What was {company}'s debt level in {year}?",
                "What were {company}'s borrowings in {year}?"
            ],
            'equity': [
                "What was {company}'s equity in {year}?",
                "How much equity did {company} have in {year}?",
                "What was {company}'s shareholders' equity in {year}?"
            ],
            'cash': [
                "How much cash did {company} have in {year}?",
                "What was {company}'s cash position in {year}?",
                "What were {company}'s cash holdings in {year}?"
            ]
        }
        
        # Extract financial data and generate Q&A pairs
        for doc_name, sections in documents.items():
            print(f"Processing document: {doc_name}")
            
            # Extract company name and year from document name
            company_match = re.search(r'(\w+)_(\d{4})', doc_name)
            if company_match:
                company, year = company_match.groups()
                company = company.upper()
                print(f"Extracted company: {company}, year: {year}")
                
                # Process each section
                for section_name, text in sections.items():
                    if not isinstance(text, str):
                        continue
                        
                    print(f"Processing section: {section_name}")
                    print(f"Section text: {text[:100]}...")
                    
                    # Extract financial metrics using FIXED processor
                    processor = FinancialProcessor()
                    financials = processor.extract_financials(text)
                    print(f"Extracted financials: {financials}")
                    
                    # Generate Q&A pairs for each metric found
                    for metric, value in financials.items():
                        if metric in question_templates:
                            for template in question_templates[metric]:
                                question = template.format(company=company, year=year)
                                answer = f"{company}'s {metric} in {year} was {value}."
                                
                                training_data.append({
                                    'question': question,
                                    'context': text[:512],  # Limit context length
                                    'answer': answer,
                                    'company': company,
                                    'year': year,
                                    'metric': metric,
                                    'section': section_name
                                })
                                print(f"Generated Q&A: {question} -> {answer}")
        
        # Add some general financial questions
        general_qa = [
            {
                'question': "How do you calculate revenue growth?",
                'context': "Financial analysis and growth calculations",
                'answer': "Revenue growth is calculated as ((Current Year Revenue - Previous Year Revenue) / Previous Year Revenue) Ã 100%.",
                'company': 'general',
                'year': 'general',
                'metric': 'calculation',
                'section': 'general'
            },
            {
                'question': "What is the debt-to-equity ratio?",
                'context': "Financial ratios and analysis",
                'answer': "Debt-to-equity ratio is calculated as Total Debt divided by Total Equity, measuring financial leverage.",
                'company': 'general',
                'year': 'general',
                'metric': 'ratio',
                'section': 'general'
            }
        ]
        
        training_data.extend(general_qa)
        self.training_data = training_data
        print(f"Total training data generated: {len(training_data)}")
        return training_data
    
    def create_simple_qa_model(self, training_data: List[Dict]):
        """Create a simple rule-based Q&A model for financial queries"""
        
        # Create a knowledge base from training data
        self.knowledge_base = {}
        
        for item in training_data:
            question_lower = item['question'].lower()
            
            # Create key patterns for matching
            key_terms = []
            if item['company'] != 'general':
                key_terms.append(item['company'].lower())
            if item['year'] != 'general':
                key_terms.append(item['year'])
            if item['metric'] != 'calculation' and item['metric'] != 'ratio':
                key_terms.append(item['metric'])
            
            key = tuple(key_terms)
            self.knowledge_base[key] = {
                'answer': item['answer'],
                'context': item['context'],
                'question': item['question']
            }
        
        print(f"Knowledge base created with {len(self.knowledge_base)} entries")
        print("Knowledge base keys:", list(self.knowledge_base.keys())[:10])  # Show first 10 keys
        
        self.model_trained = True
        return True
    
    def extract_entities_from_query(self, query: str) -> Dict[str, str]:
        """Extract company, year, and metric from query - IMPROVED"""
        entities = {'company': None, 'year': None, 'metric': None}
        
        query_lower = query.lower()
        print(f"Extracting entities from: {query_lower}")
        
        # Extract company
        company_patterns = ['tcs', 'tata consultancy services']
        for pattern in company_patterns:
            if pattern in query_lower:
                entities['company'] = 'tcs'
                break
        
        # Extract year
        year_match = re.search(r'20\d{2}', query)
        if year_match:
            entities['year'] = year_match.group()
        
        # Extract metric - improved patterns
        metric_patterns = {
            'revenue': ['revenue', 'sales'],
            'income': ['income', 'profit', 'earnings'],
            'assets': ['assets'],
            'debt': ['debt', 'borrowings'],
            'equity': ['equity'],
            'cash': ['cash']
        }
        
        for metric, patterns in metric_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                entities['metric'] = metric
                break
        
        print(f"Extracted entities: {entities}")
        return entities
    
    def answer_query(self, query: str) -> Dict[str, Any]:
        """Answer a financial query using the trained model - IMPROVED"""
        if not self.model_trained:
            return {
                'answer': "Model not trained yet. Please initialize the system first.",
                'confidence': 0.0,
                'method': 'error'
            }
        
        start_time = time.time()
        
        # Extract entities from query
        entities = self.extract_entities_from_query(query)
        
        # Try to find exact match
        key_terms = []
        if entities['company']:
            key_terms.append(entities['company'])
        if entities['year']:
            key_terms.append(entities['year'])
        if entities['metric']:
            key_terms.append(entities['metric'])
        
        exact_key = tuple(key_terms)
        print(f"Looking for exact key: {exact_key}")
        
        if exact_key in self.knowledge_base:
            result = self.knowledge_base[exact_key]
            return {
                'answer': result['answer'],
                'confidence': 0.95,
                'method': 'exact_match',
                'entities': entities,
                'response_time': time.time() - start_time,
                'context_used': result['context'][:100] + "..."
            }
        
        # Try partial matches
        best_match = None
        best_score = 0
        
        print("Trying partial matches...")
        for key, data in self.knowledge_base.items():
            score = 0
            matched_terms = []
            for term in key_terms:
                if term in key:
                    score += 1
                    matched_terms.append(term)
            
            # Normalize score
            if len(key_terms) > 0:
                score = score / len(key_terms)
            
            print(f"Key: {key}, Score: {score}, Matched: {matched_terms}")
            
            if score > best_score and score > 0.3:  # Lower threshold
                best_score = score
                best_match = data
        
        if best_match:
            return {
                'answer': best_match['answer'],
                'confidence': best_score * 0.8,  # Lower confidence for partial match
                'method': 'partial_match',
                'entities': entities,
                'response_time': time.time() - start_time,
                'context_used': best_match['context'][:100] + "..."
            }
        
        # Fallback for general financial questions
        query_lower = query.lower()
        if 'growth' in query_lower and 'revenue' in query_lower:
            return {
                'answer': "Revenue growth is typically calculated as ((Current Period Revenue - Previous Period Revenue) / Previous Period Revenue) Ã 100%. This shows the percentage increase in revenue over time.",
                'confidence': 0.7,
                'method': 'pattern_match',
                'entities': entities,
                'response_time': time.time() - start_time,
                'context_used': "General financial knowledge"
            }
        
        if 'ratio' in query_lower or ('debt' in query_lower and 'equity' in query_lower):
            return {
                'answer': "The debt-to-equity ratio measures a company's financial leverage by dividing total debt by total equity. A higher ratio indicates more debt relative to equity.",
                'confidence': 0.7,
                'method': 'pattern_match',
                'entities': entities,
                'response_time': time.time() - start_time,
                'context_used': "General financial knowledge"
            }
        
        # No match found
        return {
            'answer': "I couldn't find specific information to answer your question. Please try asking about TCS revenue, income, assets, debt, equity, or cash for 2024 or 2025.",
            'confidence': 0.1,
            'method': 'no_match',
            'entities': entities,
            'response_time': time.time() - start_time,
            'context_used': "None"
        }
    
    def get_model_stats(self) -> Dict[str, Any]:
        """Get statistics about the trained model"""
        if not self.model_trained or not self.training_data:
            return {'status': 'not_trained'}
        
        stats = {
            'status': 'trained',
            'training_samples': len(self.training_data),
            'knowledge_base_size': len(self.knowledge_base) if hasattr(self, 'knowledge_base') else 0,
            'companies': list(set([item['company'] for item in self.training_data if item['company'] != 'general'])),
            'years': list(set([item['year'] for item in self.training_data if item['year'] != 'general'])),
            'metrics': list(set([item['metric'] for item in self.training_data]))
        }
        
        return stats


def initialize_finetuned_model(documents: Dict[str, Dict]):
    """Initialize and train the fine-tuned model"""
    ft_model = FineTunedFinancialQA()
    training_data = ft_model.generate_training_data(documents)
    ft_model.create_simple_qa_model(training_data)
    return ft_model


def initialize_system(pdf_directory: str = "./data/pdfs"):
    """Initialize the financial QA system"""
    global chunks, metadata, vector_index, bm25_index, embedding_model
    
    print("=== Initializing Financial Q&A System ===")

    # Step 1: Load documents - FIXED DATA
  #  documents = {
  #      'tcs_2024': {
  #          'income': "TCS Corp 2024 Income Statement: Total revenue $4.13 billion, Net income $530 million, Operating expenses $1.5 billion, Gross profit $2.63 billion.",
  #          'balance': "TCS Corp 2024 Balance Sheet: Total assets $7.0 billion, Total debt $2.0 billion, Shareholders equity $3.5 billion, Cash and equivalents $800 million.",
  #          'general': "TCS Corp is a leading technology services company. This annual report covers fiscal year 2024 performance."
  #      },
  #      'tcs_2025': {
  #          'income': "TCS Corp 2025 Income Statement: Total revenue $4.9 billion, Net income $800 million, Operating expenses $1.7 billion, Gross profit $3.2 billion.",
  #          'balance': "TCS Corp 2025 Balance Sheet: Total assets $8.0 billion, Total debt $2.2 billion, Shareholders equity $4.0 billion, Cash and equivalents $1.1 billion.",
  #          'general': "TCS Corp continued growth in 2025 with strong performance across all business segments."
  #      }
  #  }

    documents = read_pdfs_from_directory(pdf_directory)

    if not documents:
        raise Exception("No documents could be loaded")

    # Step 2: Process documents - this updates global chunks and metadata
    chunks, metadata = process_documents(documents, chunk_sizes=[100, 400])
    if not chunks:
        raise Exception("No chunks were created from documents")

    print(f"DEBUG: Created {len(chunks)} chunks globally")

    # Step 3: Build indexes using the global chunks
    embedding_model = build_dense_index(chunks)  # Use global chunks
    if not embedding_model:
        raise Exception("Failed to build dense index")
    
    build_sparse_index(chunks)  # Use global chunks
    load_reranker()

    # Step 4: Load generator
    generator = load_generator()
    if not generator:
        raise Exception("Failed to load generator")
    
    # Save into session_state so they persist
    st.session_state.chunks = chunks
    st.session_state.metadata = metadata
    st.session_state.vector_index = vector_index
    st.session_state.bm25_index = bm25_index
    st.session_state.embedding_model = embedding_model
    st.session_state.generator = generator

    # Initialize fine-tuned model
    ft_model = initialize_finetuned_model(documents) if documents else FineTunedFinancialQA()

    print("=== System initialization completed successfully ===")
    print(f"Final status - Chunks: {len(chunks)}, Vector index: {vector_index is not None}, BM25: {bm25_index is not None}")
    return embedding_model, generator, documents, ft_model

def handle_query_pipeline(query, embedding_model_param, generator,mode="RAG System"):
    """Handle query processing pipeline"""
    if not query:
        st.error("Please enter a query")
        return
    
    # Rehydrate globals from session_state
    global chunks, metadata, vector_index, bm25_index
    chunks = st.session_state.get("chunks", [])
    metadata = st.session_state.get("metadata", [])
    vector_index = st.session_state.get("vector_index", None)
    bm25_index = st.session_state.get("bm25_index", None)
        
    start_time = time.time()
    
    try:
        print(f"DEBUG: Processing query with {len(chunks)} chunks available")
        print(f"DEBUG: Vector index available: {vector_index is not None}")
        print(f"DEBUG: BM25 index available: {bm25_index is not None}")
        
        if mode =="Fine-Tuned Model":
            result = embedding_model_param.answer_query(query)  # embedding_model_param is ft_model here
            answer = result['answer']
            confidence = result['confidence']
            response_time = time.time() - start_time
            st.markdown("### Answer")
            st.write(answer)
            st.metric("Confidence", f"{confidence:.2f}")
            st.metric("Response Time", f"{response_time:.2f}s")
            
            # Show debug info
            with st.expander("Debug Info"):
                st.json({
                    'method': result.get('method', 'unknown'),
                    'entities': result.get('entities', {}),
                    'context_used': result.get('context_used', 'N/A')
                })
            return
                 
        # Retrieval + Reranking for RAG
        retrieved = hybrid_retrieval(query, embedding_model_param)
        if not retrieved:
            st.warning("No relevant documents found for your query")
            return
        reranked = rerank_results(query, retrieved)
        answer = generate_answer(query, reranked, generator)

        output_check = output_guardrail(answer, query, reranked)
        response_time = time.time() - start_time
        
        # Display answer
        st.markdown("### Answer")
        st.write(answer)

        # System metrics
        col_a, col_b, col_c = st.columns(3)
        with col_a:
            st.metric("Confidence", f"{output_check['confidence']:.2f}")
        with col_b:
            st.metric("Response Time", f"{response_time:.2f}s")
        with col_c:
            st.metric("Sources Used", len(reranked))

        # Retrieved sources
        if reranked:
            st.markdown("### Retrieved Sources")
            for i, chunk in enumerate(reranked):
                with st.expander(f"Source {i+1} - Score: {chunk.get('combined_score', 0):.3f}"):
                    st.write(chunk['text'][:300] + "...")
                    if chunk.get('metadata'):
                        st.json(chunk['metadata'])
                        
    except Exception as e:
        st.error(f"Error processing query: {e}")
        print(f"Detailed error: {e}")

def main():
    """Main Streamlit application"""
    st.set_page_config(page_title="Comparative Financial QA System: RAG vs Fine-Tuning", layout="wide")
    
    st.title("Group 32 - Comparative Financial QA System: RAG vs Fine-Tuning")
    st.markdown("### RAG vs Fine-Tuning Comparison")
    
    # Initialize system
    if 'initialized' not in st.session_state:
        with st.spinner("Initializing system... This may take a few moments."):
            try:
                embedding_model_result, generator_result, documents, ft_model = initialize_system()
                st.session_state.embedding_model = embedding_model_result
                st.session_state.generator = generator_result
                st.session_state.documents = documents
                st.session_state.initialized = True
                st.session_state.ft_model=ft_model
                st.success("System initialized successfully!")
                
                # Show model stats
                #with st.expander("Fine-Tuned Model Stats"):
                #    stats = ft_model.get_model_stats()
                #    st.json(stats)
                    
            except Exception as e:
                st.error(f"Failed to initialize system: {e}")
                st.stop()
    
    # Sidebar
    st.sidebar.title("Settings")
    mode = st.sidebar.selectbox("Select Mode", ["RAG System", "Fine-Tuned Model"])
    
    # Main interface
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### Ask a Financial Question")
        
        # Sample questions
        sample_questions = [
            "What was TCS's revenue in 2024?",
            "How much debt did TCS have in 2025?",
            "What was TCS's net income in 2025?",
            "What are TCS's total assets in 2024?",
            "What was TCS's cash position in 2025?",
            "What was TCS's equity in 2024?"
        ]
        
        selected_sample = st.selectbox("Or select a sample question:", [""] + sample_questions)
        
        # Query input
        query = st.text_area("Enter your financial question:", 
                           value=selected_sample if selected_sample else "",
                           height=100)
        
        # Process query
        if st.button("ð Get Answer", type="primary") and query:
            # Input validation
            input_check = input_guardrail(query)
            
            if not input_check['valid']:
                st.error(f" Invalid query: {', '.join(input_check['issues'])}")
                return
            
            if mode == "RAG System":
                with st.spinner("Processing your question..."):
                    handle_query_pipeline(query, st.session_state.embedding_model, st.session_state.generator,mode="RAG System")
            elif mode == "Fine-Tuned Model":
                with st.spinner("Processing your question..."):
                    try:
                        handle_query_pipeline(query, st.session_state.ft_model, st.session_state.generator, mode="Fine-Tuned Model")
                    except Exception as e:
                        st.error(f"Error processing query: {e}")
    
    with col2:
        st.markdown("### How it Works")
        st.info("""
        **RAG System Pipeline:**
        1. Document chunking
        2. Dense & sparse retrieval
        3. Hybrid ranking
        4. Result reranking
        5. Answer generation
        
        **Fine-Tuned Model:**
        1. Extract entities from query
        2. Match against knowledge base
        3. Return structured answer
        """)
        
        st.markdown("### Sample Data")
        if st.session_state.get('documents'):
            st.write("**Companies:** TCS Corp")
            st.write("**Years:** 2024, 2025")
            st.write("**Sections:** Income Statement, Balance Sheet")
            st.write(f"**Documents loaded:** {len(st.session_state.documents)}")
        
     
if __name__ == "__main__":
    main()